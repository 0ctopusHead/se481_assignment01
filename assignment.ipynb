{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:31.066754Z",
     "end_time": "2023-11-26T16:10:31.082388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yanwarutsuksawat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yanwarutsuksawat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('','',\n",
    "                                                                                string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(\n",
    "        lambda s: s.translate(\n",
    "            str.maketrans(string.whitespace, ' ' * len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description\n",
    "\n",
    "\n",
    "def simple_tokenize(data):\n",
    "    clean_description = data.apply(lambda s: [x.strip() for x in s.split()])\n",
    "    return clean_description\n",
    "\n",
    "\n",
    "def parse_job_description():\n",
    "    clean_description = get_and_clean_data()\n",
    "    clean_description = simple_tokenize(clean_description)\n",
    "    return clean_description\n",
    "\n",
    "\n",
    "def count_java():\n",
    "    parse_description = parse_job_description()\n",
    "    count_java = parse_description.apply(lambda s: 'java' in s).sum()\n",
    "    print('java: ' + str(count_java) + ' of ' + str(\n",
    "        parse_description.shape[0]))\n",
    "\n",
    "\n",
    "def parse_db():\n",
    "    html_doc = requests.get(\"https://db-engines.com/en/ranking\").content\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    db_table = soup.find(\"table\", {\"class\": \"dbi\"})  # find the table that class=\"dbi\"\n",
    "    all_db = [''.join(s.find('a').findAll(string=True, recursive=False)).strip() for s in\n",
    "              db_table.findAll(\"th\", {\n",
    "                  \"class\": \"pad-l\"})]\n",
    "    all_db = list(dict.fromkeys(all_db))\n",
    "    db_list = all_db[:10]\n",
    "    db_list = [s.lower() for s in db_list]\n",
    "    db_list = [[x.strip() for x in s.split()] for s in\n",
    "               db_list]\n",
    "    return db_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:31.078315Z",
     "end_time": "2023-11-26T16:10:31.082962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "cleaned_db = parse_db()\n",
    "parse_description = parse_job_description()\n",
    "raw = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "  raw[i] = parse_description.apply(lambda s: np.all([x in s for x in db])).sum()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:31.087106Z",
     "end_time": "2023-11-26T16:10:43.796012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "with_java = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    with_java[i] = parse_description.apply(lambda s: np.all([x in s for x in db]) and 'java' in s).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:43.850630Z",
     "end_time": "2023-11-26T16:10:44.285286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + java: 913 of 1392 (65.59%)\n",
      "mysql + java: 397 of 667 (59.52%)\n",
      "microsoft sql server + java: 239 of 868 (27.53%)\n",
      "postgresql + java: 161 of 261 (61.69%)\n",
      "mongodb + java: 166 of 296 (56.08%)\n",
      "redis + java: 40 of 106 (37.74%)\n",
      "elasticsearch + java: 112 of 161 (69.57%)\n",
      "ibm db2 + java: 33 of 48 (68.75%)\n",
      "sqlite + java: 5 of 28 (17.86%)\n",
      "microsoft access + java: 78 of 256 (30.47%)\n"
     ]
    }
   ],
   "source": [
    "for i, db in enumerate(cleaned_db):\n",
    "    print(' '.join(db) + ' + java: ' + str(with_java[i]) + ' of ' + str(raw[i]) + ' (' +\n",
    "          str(np.around(with_java[i] / raw[i] * 100, 2)) + '%)')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:44.286852Z",
     "end_time": "2023-11-26T16:10:44.289386Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.) What DB should I learn after java?\n",
    "  - Ans: elasticsearch or ibm db2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "with_oracle = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    with_oracle[i] = parse_description.apply(lambda s: np.all([x in s for x in db]) and 'oracle' in s).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:44.296297Z",
     "end_time": "2023-11-26T16:10:44.797311Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + oracle: 1392 of 1392 (100.0%)\n",
      "mysql + oracle: 312 of 667 (46.78%)\n",
      "microsoft sql server + oracle: 195 of 868 (22.47%)\n",
      "postgresql + oracle: 100 of 261 (38.31%)\n",
      "mongodb + oracle: 104 of 296 (35.14%)\n",
      "redis + oracle: 12 of 106 (11.32%)\n",
      "elasticsearch + oracle: 32 of 161 (19.88%)\n",
      "ibm db2 + oracle: 23 of 48 (47.92%)\n",
      "sqlite + oracle: 17 of 28 (60.71%)\n",
      "microsoft access + oracle: 51 of 256 (19.92%)\n"
     ]
    }
   ],
   "source": [
    "for i, db in enumerate(cleaned_db):\n",
    "    print(' '.join(db) + ' + oracle: ' + str(with_oracle[i]) + ' of ' + str(raw[i]) + ' (' +\n",
    "          str(np.around(with_oracle[i] / raw[i] * 100, 2)) + '%)')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:10:44.797532Z",
     "end_time": "2023-11-26T16:10:44.803057Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.) Which DB is in demand alongside oracle?\n",
    "   - Ans: sqlite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java + python: 830 of 1379\n",
      "python + python: 1379 of 1379\n",
      "c + python: 689 of 1379\n",
      "kotlin + python: 6 of 1379\n",
      "swift + python: 37 of 1379\n",
      "rust + python: 6 of 1379\n",
      "ruby + python: 181 of 1379\n",
      "scala + python: 76 of 1379\n",
      "julia + python: 1 of 1379\n",
      "lua + python: 11 of 1379\n",
      "java + python: 830 of 1379 (60.19%)\n",
      "python + python: 1379 of 1379 (100.0%)\n",
      "c + python: 689 of 1379 (49.96%)\n",
      "kotlin + python: 6 of 1379 (0.44%)\n",
      "swift + python: 37 of 1379 (2.68%)\n",
      "rust + python: 6 of 1379 (0.44%)\n",
      "ruby + python: 181 of 1379 (13.13%)\n",
      "scala + python: 76 of 1379 (5.51%)\n",
      "julia + python: 1 of 1379 (0.07%)\n",
      "lua + python: 11 of 1379 (0.8%)\n"
     ]
    }
   ],
   "source": [
    "lang = [['java'], ['python'], ['c'], ['kotlin'], ['swift'], ['rust'], ['ruby'], ['scala'], ['julia'], ['lua']]\n",
    "parsed_description = parse_job_description()\n",
    "parsed_db = parse_db()\n",
    "all_terms = lang + parsed_db\n",
    "\n",
    "query_map = pd.DataFrame(parsed_description.apply(lambda s: [1 if np.all([d in s for d in db])\n",
    "                                                             else 0 for db in all_terms]).values.tolist(),\n",
    "                         columns=[' '.join(d) for d in all_terms])\n",
    "\n",
    "\n",
    "q1 = query_map[query_map['python'] > 0].apply(lambda s: np.where(s == 1)[0],\n",
    "                                                    axis=1).apply(lambda s: list(query_map.columns[s]))\n",
    "with_python = [None] * len(lang)\n",
    "raw = [None] * len(lang)\n",
    "for i, langs in enumerate(lang):\n",
    "    with_python[i] = q1.apply(lambda s: np.all([x in s for x in langs]) and 'python' in s).sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:58:38.889820Z",
     "end_time": "2023-11-26T16:58:44.377043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java + python: 830 of 1379 (60.19%)\n",
      "python + python: 1379 of 1379 (100.0%)\n",
      "c + python: 689 of 1379 (49.96%)\n",
      "kotlin + python: 6 of 1379 (0.44%)\n",
      "swift + python: 37 of 1379 (2.68%)\n",
      "rust + python: 6 of 1379 (0.44%)\n",
      "ruby + python: 181 of 1379 (13.13%)\n",
      "scala + python: 76 of 1379 (5.51%)\n",
      "julia + python: 1 of 1379 (0.07%)\n",
      "lua + python: 11 of 1379 (0.8%)\n"
     ]
    }
   ],
   "source": [
    "for i, langs in enumerate(lang):\n",
    "    print(' '.join(langs) + ' + python: ' + str(with_python[i]) + ' of ' + str(q1.shape[0]) + ' (' +\n",
    "            str(np.around(with_python[i] / q1.shape[0] * 100, 2)) + '%)')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T16:59:28.215928Z",
     "end_time": "2023-11-26T16:59:28.220530Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.) What programing language is in demand alongside python?\n",
    "  - Ans: Java"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.) Create one question beginning with \"WHY\" that can be answered using the data we've analyzed during this class. Then, provide your solution to the question.\n",
    "- Why do we need to learn Microsoft Sql Server after learning C?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + c: 511 of 1392 (36.71%)\n",
      "mysql + c: 278 of 667 (41.68%)\n",
      "microsoft sql server + c: 658 of 868 (75.81%)\n",
      "postgresql + c: 92 of 261 (35.25%)\n",
      "mongodb + c: 99 of 296 (33.45%)\n",
      "redis + c: 36 of 106 (33.96%)\n",
      "elasticsearch + c: 54 of 161 (33.54%)\n",
      "ibm db2 + c: 13 of 48 (27.08%)\n",
      "sqlite + c: 16 of 28 (57.14%)\n",
      "microsoft access + c: 192 of 256 (75.0%)\n"
     ]
    }
   ],
   "source": [
    "cleaned_db = parse_db()\n",
    "parse_description = parse_job_description()\n",
    "raw = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    raw[i] = parse_description.apply(lambda s: np.all([x in s for x in db])).sum()\n",
    "\n",
    "with_c = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    with_c[i] = parse_description.apply(lambda s: np.all([x in s for x in db]) and 'c' in s).sum()\n",
    "\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    print(' '.join(db) + ' + c: ' + str(with_c[i]) + ' of ' + str(raw[i]) + ' (' +\n",
    "              str(np.around(with_c[i] / raw[i] * 100, 2)) + '%)')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-26T17:18:32.885341Z",
     "end_time": "2023-11-26T17:18:38.473428Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solution -> Based on the data. the percentage that Microsoft Sql Server appearing in the job description document is significantly high from other DBMS."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
